{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM/oBTeuHBBIhvyvTr+teKl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juyee1698/Electra/blob/main/Music_Generation(Bi_LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "NTZOCM2Y3peI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Omj-S1tRY_f9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import glob\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from music21 import converter, instrument, stream, note, chord\n",
        "\n",
        "#Run version 2.1.6\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation, Bidirectional, Flatten\n",
        "from keras import utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "from keras.layers import GlobalMaxPooling1D, MaxPooling1D\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDWIRbiIL-_B"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj7DAyokDKYv"
      },
      "source": [
        "!pip install keras_self_attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation & Model training"
      ],
      "metadata": {
        "id": "UflLmi_sEENz"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez5SLj23ZY5D"
      },
      "source": [
        "def train_network(notes, n_vocab):\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "\n",
        "    train(model, network_input, network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmNnObzMLnQf"
      },
      "source": [
        "network_input, network_output = prepare_sequences(notes, n_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the notes and chords object for each instrument"
      ],
      "metadata": {
        "id": "8uiZ-zwMEboj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHFXsr8PZbeJ"
      },
      "source": [
        "def get_notes():\n",
        "    notes = []\n",
        "    durations = []\n",
        "\n",
        "    for file in glob.glob(\"/content/park/*.mid\"):\n",
        "        midi = converter.parse(file)\n",
        "\n",
        "        print(\"Parsing %s\" % file)\n",
        "\n",
        "        notes_to_parse = None\n",
        "\n",
        "        try: # file has instrument parts\n",
        "            s2 = instrument.partitionByInstrument(midi) #Currently we are only working with piano\n",
        "            for part in s2:\n",
        "              if isinstance(part.getInstrument(), instrument.Piano):\n",
        "                print(\"True\")\n",
        "                notes_to_parse = part.recurse()\n",
        "                print(len(notes_to_parse))\n",
        "            #notes_to_parse = s2.parts[0].recurse()\n",
        "        except: # file has notes in a flat structure\n",
        "            notes_to_parse = midi.flat.notes\n",
        "            print(len(notes_to_parse))\n",
        "\n",
        "        try:\n",
        "          for element in notes_to_parse:\n",
        "              if isinstance(element, note.Note):\n",
        "                  notes.append(str(element.pitch) + \" \" +  str(element.quarterLength))\n",
        "              elif isinstance(element, chord.Chord):\n",
        "                  notes.append('.'.join(str(n) for n in element.normalOrder) + \" \" + str(element.quarterLength))\n",
        "              elif isinstance(element, note.Rest):\n",
        "                  notes.append(str(element.name)  + \" \" + str(element.quarterLength))\n",
        "        except:\n",
        "          continue\n",
        "\n",
        "    print(\"Notes\",notes)\n",
        "\n",
        "    return notes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare input and output sequences for the model to learn"
      ],
      "metadata": {
        "id": "PTKm2XhcEp5T"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdDq9_yxZfNA"
      },
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 100 #Track will be divided into sequences of 100 notes/chords for the model to learn\n",
        "\n",
        "    # get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    #print(pitchnames)\n",
        "\n",
        "     # create a dictionary to map pitches to integers\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "        #print(\"Network Output \",network_output)\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "    print(n_patterns)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    print(len(set(network_output)))\n",
        "    network_output = to_categorical(network_output)\n",
        "    print(len(network_output))\n",
        "    print(network_input.shape[1],network_input.shape[2])\n",
        "    print(network_output.shape)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build and configure the ML model"
      ],
      "metadata": {
        "id": "tJRvlY8UGGOr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tICdOx42Zl71"
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]), #n_time_steps, n_features?\n",
        "        return_sequences=True)))\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(LSTM(512,return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    #model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    learning_rate = 0.005\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "    #model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    #      from_logits=True), optimizer=optimizer)\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    return model\n",
        "\n",
        "def train(model, network_input, network_output):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    filepath = os.path.abspath(\"weights-3LSTMAttLayer-final.hdf5\")\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        period=10, #Every 10 epochs\n",
        "        monitor='loss',\n",
        "        verbose=1,\n",
        "        patience=5,\n",
        "        save_weights_only=True,\n",
        "        restore_best_weights=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    model.fit(network_input, network_output, epochs=200, batch_size=32, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvJRPHyRZogT"
      },
      "source": [
        "#load files in\n",
        "notes = get_notes()\n",
        "\n",
        "# get amount of pitch names\n",
        "n_vocab = len(set(notes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-QQE2qMDkE5",
        "outputId": "fcb04c57-b7cd-4a4a-f675-908a59323678"
      },
      "source": [
        "n_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "693"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Model"
      ],
      "metadata": {
        "id": "RANKUIUWGQuu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnOD9rYwZrpW"
      },
      "source": [
        "#train\n",
        "train_network(notes, n_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HXJZ0NQIagi"
      },
      "source": [
        "# model = Sequential()\n",
        "# model.add(Bidirectional(LSTM(512,return_sequences=True),input_shape=(network_input.shape[1], network_input.shape[2]))) #n_time_steps, n_features? Needed input_shape in first layer, which is Bid not LSTM\n",
        "# model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "# model.add(LSTM(512,return_sequences=True))\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "# #model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "# model.add(Dense(n_vocab))\n",
        "# model.add(Activation('softmax'))\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "# model.load_weights('/content/weights-3LSTMAttLayer-final.hdf5')\n",
        "# train(model, network_input, network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate output sequence"
      ],
      "metadata": {
        "id": "CgBqjqxnGUSn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej-b79CEBKwL"
      },
      "source": [
        "def generate():\n",
        "    \"\"\" Generate a piano midi file \"\"\"\n",
        "    #load the notes used to train the model\n",
        "    # with open('data/notes', 'rb') as filepath:\n",
        "    #     notes = pickle.load(filepath)\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    # Get all pitch names\n",
        "    n_vocab = len(set(notes))\n",
        "\n",
        "    network_input, normalized_input = prepare_sequences_output(notes, pitchnames, n_vocab)\n",
        "    model = create_network_add_weights(normalized_input, n_vocab)\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgKLAse3BNwT"
      },
      "source": [
        "def prepare_sequences_output(notes, pitchnames, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    # map between notes and integers and back\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 25\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGme3rdZBSVv"
      },
      "source": [
        "def create_network_add_weights(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Bidirectional(LSTM(512,return_sequences=True),input_shape=(network_input.shape[1], network_input.shape[2]))) #n_time_steps, n_features? Needed input_shape in first layer, which is Bid not LSTM\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    #model.add(LSTM(512,return_sequences=True))\n",
        "    #model.add(Dropout(0.3))\n",
        "\n",
        "    #model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "    # Load the weights to each node\n",
        "    model.load_weights('/content/weights-3LSTMAttLayer-final.hdf5')\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model uses its weights to predict the next note in the sequence based on the previous sequences"
      ],
      "metadata": {
        "id": "uDbVMx-oGqt2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug1oFz4ABaDr"
      },
      "source": [
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = np.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(150):\n",
        "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "        index = np.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    print(prediction_output)\n",
        "\n",
        "    return prediction_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create MIDI file"
      ],
      "metadata": {
        "id": "SbXuu4rpG_T5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvNMk1urBgZh"
      },
      "source": [
        "def create_midi(prediction_output):\n",
        "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
        "        from the notes \"\"\"\n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "    output_notes.append(instrument.Piano())\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        pattern = pattern.split()\n",
        "        temp = pattern[0]\n",
        "        duration = pattern[1]\n",
        "        pattern = temp\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a rest\n",
        "        elif('rest' in pattern):\n",
        "            new_rest = note.Rest(pattern)\n",
        "            new_rest.offset = offset\n",
        "            new_rest.storedInstrument = instrument.Piano() #???\n",
        "            output_notes.append(new_rest)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)\n",
        "    midi_stream.write('midi', fp='piano_comp_29092021.mid')\n",
        "\n",
        "#From: https://stackoverflow.com/questions/1806278/convert-fraction-to-float\n",
        "def convert_to_float(frac_str):\n",
        "    try:\n",
        "        return float(frac_str)\n",
        "    except ValueError:\n",
        "        num, denom = frac_str.split('/')\n",
        "        try:\n",
        "            leading, num = num.split(' ')\n",
        "            whole = float(leading)\n",
        "        except ValueError:\n",
        "            whole = 0\n",
        "        frac = float(num) / float(denom)\n",
        "        return whole - frac if whole < 0 else whole + frac"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jegeN-iABnOY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0580b5d8-b3d1-4fae-c79e-49b0d0af66b5"
      },
      "source": [
        "generate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['9.1 0.5', 'B5 7/3', 'F6 0.75', 'E3 2.0', 'B-5 4/3', '2.6.9 2.5', 'G#5 1.5', 'B-4 1/3', 'B4 8.25', 'C#5 0.75', '7.11 5/3', '8.11 2.0', '0.2 2.0', '6.8 1/3', 'E-4 4.0', 'F#2 3.0', '6.9.1 1.0', 'C4 1.75', '2.6 2.0', 'F#5 3.0', '8.11 2.0', '4.7 4.0', 'C5 4.0', '1 1.0', 'E4 4.0', '9.0 6.0', 'B-2 0.75', 'E3 7.0', 'B-3 1.5', '7.11 4/3', 'G#5 4.0', 'E4 4.0', '4.9 1.5', '2.7 1.0', '2.7 1.25', '7.11 0.25', 'B2 0.75', '8.10 1.0', 'G2 2.75', '4.8 2.0', '2 7.75', '11.1 5.0', 'F#2 3.0', '5.7 2.0', '1.4.8 3.0', 'B2 0.75', '0.2.7 4.0', '2.7 1.25', '7.0 0.25', '2.7 5/3', 'E4 4.0', '0.4 1.0', '5.10 2.0', 'B2 0.75', '0.4.7 4.0', 'E4 4.0', '1.6 3.0', '6.11 4.0', '6.11 4.0', 'C3 3.0', '9.0 6.0', '11.1.6 3.0', 'E2 5.0', '6.11 2.75', '0.2.7 4.0', '1 0.5', '4.9 4/3', '2.7 5/3', '11 7.0', '7.0 0.25', '8.10 1.0', '8.10 1.0', 'E3 3.75', '4.8 2.0', 'C4 1.75', '1 1.0', '7.0 0.5', 'E3 3.75', 'G5 3.5', 'C#6 2.0', '10 5.0', '7.10 1.0', '5.10 1.5', '4.9 4/3', 'E5 7/3', 'B2 0.75', 'C4 1.75', 'G#5 1.5', 'E5 3.25', '6.8 1.0', 'B5 7/3', 'B-6 4.0', 'B-6 4.0', '11.2 2.0', '9.0 1/3', '7.11 0.25', '9.2 2.75', '2 7.75', '4.9 4/3', 'E5 7/3', 'F6 0.75', 'E6 8/3', '6.7.11.2 8.0', 'C2 1.0', '6.11 2.0', 'B-4 3.25', '7.11 0.25', '6.11 4.0', '8.11 2.0', 'F4 2.25', 'G4 4.5', 'E6 8/3', 'E6 8/3', 'G2 7.0', 'E5 3.25', 'C4 10/3', 'G3 6.0', 'E5 3.25', 'E5 3.25', 'E5 3.25', 'E5 3.25', 'C6 3.25', 'E6 3.0', '6.9.1 1.0', '7.0 1.75', '2 8.0', '1.2.4 0.5', '4.9 4/3', 'F#5 1/3', 'G#5 4.0', 'C6 3.25', 'E5 3.25', 'E5 3.25', 'C4 0.25', 'B4 1.75', 'E-7 0.25', '10.3 4.0', 'G#5 3.75', '4.8 2.0', '11.3 7/3', 'F3 2.0', '3.6 4.0', '4.7 4.0', 'C5 4.0', '1 8.0', '11.3.6 4.0', '2.7 1.25', '2.7 5/3', 'E5 3.25', '4.8 2.0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjJem7RNg_Z3"
      },
      "source": [
        "def plot_piano_roll(notes: pd.DataFrame, count: Optional[int] = None):\n",
        "  if count:\n",
        "    title = f'First {count} notes'\n",
        "  else:\n",
        "    title = f'Whole track'\n",
        "    count = len(notes['pitch'])\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  plot_pitch = np.stack([notes['pitch'], notes['pitch']], axis=0)\n",
        "  plot_start_stop = np.stack([notes['start'], notes['end']], axis=0)\n",
        "  plt.plot(\n",
        "      plot_start_stop[:, :count], plot_pitch[:, :count], color=\"b\", marker=\".\")\n",
        "  plt.xlabel('Time [s]')\n",
        "  plt.ylabel('Pitch')\n",
        "  _ = plt.title(title)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}